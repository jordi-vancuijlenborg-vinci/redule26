{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM6BF0VflLLSN371h7Y9PwM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/redule26/redule26/blob/main/Bloom_BigScience_Experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M5txOVyROBe",
        "outputId": "3cb507ad-94b9-4cda-aa66-ee4f2edbb587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: transformers\n",
            "Version: 4.28.1\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, tokenizers, tqdm\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxYlpUYaRrrY",
        "outputId": "bba4e4b3-88c5-4b22-a14c-f3d10b9105e9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel, set_seed, AutoModelForCausalLM"
      ],
      "metadata": {
        "id": "R95zIL7BR5gU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
      ],
      "metadata": {
        "id": "AyTq6wqrU2QU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-1b7\")"
      ],
      "metadata": {
        "id": "eql6NAC_R-2O"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lm = AutoModelForCausalLM.from_pretrained(\"bigscience/bloom-1b7\")"
      ],
      "metadata": {
        "id": "UBSaqJfIVmRD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lm.__class__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E6vUE9UXGxV",
        "outputId": "40604695-4604-4ea8-cfc4-8c47f3530d27"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.models.bloom.modeling_bloom.BloomForCausalLM"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_lm.__class__.__name__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ODWgiuUbScJG",
        "outputId": "65646592-37b6-47a7-ac3d-08bc377fbe46"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'BloomForCausalLM'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(11111)"
      ],
      "metadata": {
        "id": "crWBOaquSuUv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_prompt = 'How are you ?'"
      ],
      "metadata": {
        "id": "3kDdsdasTMy1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_tokens = tokenizer(text_prompt, return_tensors=\"pt\").to(0)"
      ],
      "metadata": {
        "id": "sS_qpSn-TWTb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_sample = model_lm.generate(**input_tokens, max_length=200, top_k=0, temperature=0.5)"
      ],
      "metadata": {
        "id": "4O0CIdY-WFXa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZbnZZAQWL3H",
        "outputId": "532e3ab3-1e04-45be-d180-2948bced6e59"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  7572,   1306,   1152,   2040,      5,    603,      5,  10203,   1728,\n",
              "           4548,     15,      5,   7555,    368,   1517,     15,    567,   5814,\n",
              "            473,   5926,   4472,   3595,    427,    727,     17,      5,    603,\n",
              "              5,  23857,   1130,     34,      5,    603,      5,  23682,   8610,\n",
              "            267,  29978,   1485,   2670,  32531,     17,      5,    603,      5,\n",
              "          12620,   2632,  32531,     34,      5,    603, 202864,     17,      5,\n",
              "            603,      5,  32477,    632,   7154,     34,      5,    603,      5,\n",
              "           5715,  10863,     17,      5,    603,      5,   5715,  10863,     34,\n",
              "              5,    603, 202864,     17,      5,    603,      5,  32477,    632,\n",
              "           7154,     34,      5,    603,      5,   5715,  10863,     17,      5,\n",
              "            603,      5,   5715,  10863,     34,      5,    603, 202864,     17,\n",
              "              5,    603,      5,  32477,    632,   7154,     34,      5,    603,\n",
              "              5,   5715,  10863,     17,      5,    603,      5,   5715,  10863,\n",
              "             34,      5,    603, 202864,     17,      5,    603,      5,  32477,\n",
              "            632,   7154,     34,      5,    603,      5,   5715,  10863,     17,\n",
              "              5,    603,      5,   5715,  10863,     34,      5,    603, 202864,\n",
              "             17,      5,    603,      5,  32477,    632,   7154,     34,      5,\n",
              "            603,      5,   5715,  10863,     17,      5,    603,      5,   5715,\n",
              "          10863,     34,      5,    603, 202864,     17,      5,    603,      5,\n",
              "          32477,    632,   7154,     34,      5,    603,      5,   5715,  10863,\n",
              "             17,      5,    603,      5,   5715,  10863,     34,      5,    603,\n",
              "         202864,     17,      5,    603,      5,  32477,    632,   7154,     34,\n",
              "              5,    603]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(result_sample[0], truncate_before_pattern=[r\"\\n\\n^#\", \"^'''\", \"\\n\\n\\n\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2LrE-6XWPjs",
        "outputId": "c46dc36d-2ef9-4545-c0f5-4f7a281d57c9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How are you ?\"\n",
            "\n",
            "\"I'm all right,\" said the man, \"but I don't know what to do.\"\n",
            "\n",
            "\"Why not?\"\n",
            "\n",
            "\"I've got a letter from my wife.\"\n",
            "\n",
            "\"From your wife?\"\n",
            "\n",
            "\"Yes.\"\n",
            "\n",
            "\"Where is she?\"\n",
            "\n",
            "\"At home.\"\n",
            "\n",
            "\"At home?\"\n",
            "\n",
            "\"Yes.\"\n",
            "\n",
            "\"Where is she?\"\n",
            "\n",
            "\"At home.\"\n",
            "\n",
            "\"At home?\"\n",
            "\n",
            "\"Yes.\"\n",
            "\n",
            "\"Where is she?\"\n",
            "\n",
            "\"At home.\"\n",
            "\n",
            "\"At home?\"\n",
            "\n",
            "\"Yes.\"\n",
            "\n",
            "\"Where is she?\"\n",
            "\n",
            "\"At home.\"\n",
            "\n",
            "\"At home?\"\n",
            "\n",
            "\"Yes.\"\n",
            "\n",
            "\"Where is she?\"\n",
            "\n",
            "\"At home.\"\n",
            "\n",
            "\"At home?\"\n",
            "\n",
            "\"Yes.\"\n",
            "\n",
            "\"Where is she?\"\n",
            "\n",
            "\"At home.\"\n",
            "\n",
            "\"At home?\"\n",
            "\n",
            "\"Yes.\"\n",
            "\n",
            "\"Where is she?\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}